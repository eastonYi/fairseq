DATA_DIR=./data/aishell2/preprocessed_data_vq
SAVE_DIR=./exp/vq_wav2vec_aishell2_bert_finetune/decode_result_best/
MODEL_PATH=./exp/vq_wav2vec_aishell2_bert_finetune/checkpoint_best.pt
#### CUDA_VISIBLE_DEVICES=0 nohup python examples/speech_recognition/infer_vq.py $DATA_DIR --task speech_recognition_vq --max-tokens 45000 --nbest 1 --path $MODEL_PATH --lm-beam 300 --results-path $SAVE_DIR --batch-size 40 --gen-subset "android_dev_200" --user-dir examples/speech_recognition/ --criterion ctc_loss --no-progress-bar --lm-alpha 1.0 --lm-beta -1.0 --lm-model-path "./data/aishell2/preprocessed_data_vq/text.aishell2.4gram.arpa.bin" > nohup.out &
CUDA_VISIBLE_DEVICES=0 nohup python examples/speech_recognition/infer_vq.py $DATA_DIR --task speech_recognition_vq --max-tokens 45000 --nbest 1 --path $MODEL_PATH --lm-beam 300 --results-path $SAVE_DIR --batch-size 40 --gen-subset "android_dev_200" --user-dir examples/speech_recognition/ --criterion ctc_loss --no-progress-bar > nohup.out &
#### CUDA_VISIBLE_DEVICES=1 nohup python examples/speech_recognition/infer_vq.py $DATA_DIR --task speech_recognition_vq --max-tokens 45000 --nbest 1 --path $MODEL_PATH --lm-beam 300 --results-path $SAVE_DIR --batch-size 40 --gen-subset "android_test" --user-dir examples/speech_recognition/ --criterion ctc_loss --no-progress-bar --lm-alpha 0.5 --lm-beta 1.0 --lm-model-path "./data/aishell2/preprocessed_data_vq/text.aishell2.4gram.arpa.bin" > nohup.out1 &
#### CUDA_VISIBLE_DEVICES=2 nohup python examples/speech_recognition/infer_vq.py $DATA_DIR --task speech_recognition_vq --max-tokens 45000 --nbest 1 --path $MODEL_PATH --lm-beam 300 --results-path $SAVE_DIR --batch-size 40 --gen-subset "ios_dev" --user-dir examples/speech_recognition/ --criterion ctc_loss --no-progress-bar --lm-alpha 0.5 --lm-beta 1.0 --lm-model-path "./data/aishell2/preprocessed_data_vq/text.aishell2.4gram.arpa.bin" > nohup.out2 &
#### CUDA_VISIBLE_DEVICES=3 nohup python examples/speech_recognition/infer_vq.py $DATA_DIR --task speech_recognition_vq --max-tokens 45000 --nbest 1 --path $MODEL_PATH --lm-beam 300 --results-path $SAVE_DIR --batch-size 40 --gen-subset "ios_test" --user-dir examples/speech_recognition/ --criterion ctc_loss --no-progress-bar --lm-alpha 0.5 --lm-beta 1.0 --lm-model-path "./data/aishell2/preprocessed_data_vq/text.aishell2.4gram.arpa.bin" > nohup.out3 &
